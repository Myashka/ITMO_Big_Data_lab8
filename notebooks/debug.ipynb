{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/openfood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       85.0\n",
       "1      571.0\n",
       "2      167.0\n",
       "3      250.0\n",
       "4      153.0\n",
       "       ...  \n",
       "995    467.0\n",
       "996    192.0\n",
       "997     48.0\n",
       "998     56.0\n",
       "999    536.0\n",
       "Name: energy_kcal_100g, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['energy_kcal_100g'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/openfood.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['energy-kcal_100g'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10076064010494"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10076064010467 - 2^31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10076064010467"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['code'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       85.0\n",
       "1      571.0\n",
       "2      167.0\n",
       "3      250.0\n",
       "4      153.0\n",
       "       ...  \n",
       "995    467.0\n",
       "996    192.0\n",
       "997     48.0\n",
       "998     56.0\n",
       "999    536.0\n",
       "Name: energy-kcal_100g, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['energy-kcal_100g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       85.0\n",
       "1      571.0\n",
       "2      167.0\n",
       "3      250.0\n",
       "4      153.0\n",
       "       ...  \n",
       "995    467.0\n",
       "996    192.0\n",
       "997     48.0\n",
       "998     56.0\n",
       "999    536.0\n",
       "Name: energy-kcal_100g, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['energy-kcal_100g'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code                         int64\n",
      "product_name                object\n",
      "energy-kcal_100g           float64\n",
      "energy_100g                float64\n",
      "fat_100g                   float64\n",
      "saturated-fat_100g         float64\n",
      "trans-fat_100g             float64\n",
      "cholesterol_100g           float64\n",
      "carbohydrates_100g         float64\n",
      "sugars_100g                float64\n",
      "fiber_100g                 float64\n",
      "proteins_100g              float64\n",
      "salt_100g                  float64\n",
      "sodium_100g                float64\n",
      "calcium_100g               float64\n",
      "iron_100g                  float64\n",
      "nutrition-score-fr_100g    float64\n",
      "categories_en               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 12:09:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"WordCountInline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 13:09:54 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "24/05/20 13:09:54 INFO SparkUI: Stopped Spark web UI at http://192.168.194.153:4040\n",
      "24/05/20 13:09:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "24/05/20 13:09:54 INFO MemoryStore: MemoryStore cleared\n",
      "24/05/20 13:09:54 INFO BlockManager: BlockManager stopped\n",
      "24/05/20 13:09:54 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "24/05/20 13:09:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "24/05/20 13:09:54 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/features.json', \"r\") as columns_file:\n",
    "    features = json.load(columns_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql import types, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: pyspark.sql.DataFrame = spark.read.csv('../data/openfood.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_COLUMN = \"scaled_feature\"\n",
    "\n",
    "id_columns = features[\"id\"]\n",
    "feature_numeric = features[\"numeric\"]\n",
    "numeric_columns = [\n",
    "    functions.col(c).cast(\"float\").alias(c) for c in feature_numeric\n",
    "]\n",
    "cat_columns = features[\"categorical\"]\n",
    "\n",
    "all_columns = id_columns + numeric_columns + cat_columns\n",
    "df_with_selected_columns = dataset.select(*all_columns)\n",
    "\n",
    "vec_assembler = VectorAssembler(\n",
    "    inputCols=feature_numeric, outputCol=\"features\"\n",
    ")\n",
    "df_with_features = vec_assembler.transform(df_with_selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=FEATURES_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 12:09:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "scaler_model = scaler.fit(df_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_features = scaler_model.transform(df_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 12:09:34 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_feature\")\n",
    "scaler_model = scaler.fit(df_with_features)\n",
    "df_scaled_features = scaler_model.transform(df_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import clustering, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clustering.KMeans(featuresCol=\"scaled_feature\", k=5, maxIter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 12:11:09 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/21 12:11:09 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(df_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_fit.transform(df_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.withColumn(\"prediction\", output.prediction.cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- energy-kcal_100g: float (nullable = true)\n",
      " |-- energy_100g: float (nullable = true)\n",
      " |-- fat_100g: float (nullable = true)\n",
      " |-- saturated-fat_100g: float (nullable = true)\n",
      " |-- trans-fat_100g: float (nullable = true)\n",
      " |-- cholesterol_100g: float (nullable = true)\n",
      " |-- carbohydrates_100g: float (nullable = true)\n",
      " |-- sugars_100g: float (nullable = true)\n",
      " |-- fiber_100g: float (nullable = true)\n",
      " |-- proteins_100g: float (nullable = true)\n",
      " |-- salt_100g: float (nullable = true)\n",
      " |-- sodium_100g: float (nullable = true)\n",
      " |-- calcium_100g: float (nullable = true)\n",
      " |-- iron_100g: float (nullable = true)\n",
      " |-- nutrition-score-fr_100g: float (nullable = true)\n",
      " |-- categories_en: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_feature: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
